
# ARCore系列文章之二：------  Google ARCore介绍


  - [一、ARCore介绍](#一、ARCore介绍)
  - [二、ARCore工作原理](#二、ARCore工作原理)
  - [三、ARCore基本概念](#三、ARCore基本概念)
  - [四、ARCore渲染技术](#四、ARCore渲染技术)
  	- [使用OpenGL渲染](#使用OpenGL渲染)
	- [使用Sceneform渲染](#使用Sceneform渲染)

## 一、ARCore介绍

ARCore是Google于2017年08月29日发布的一套用来创建AR(augmented reality) App的SDK。 官方网站是https://developers.google.com/ar/develop/。

ARCore可以在现下多种流行开发平台中使用. 它本身封装了一套本地API，通过它可以实现一些最基础的AR效果：比如 手势监听、世界的定义、灯光识别 等 通俗来讲就是在用户视觉(主要是Camera)的基础上，覆盖一些3D模型，这些模型可以是世界事物或者各种角色。
 

![](https://user-gold-cdn.xitu.io/2018/6/23/1642c3f0f6fd4d1c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 二、ARCore工作原理

ARCore的原理主要是集成了设备Camera中的加速传感器、陀螺仪、上下文识别信息等功能。首先它从Camera环境中甄别出一些可视的特征, 并通过手势追踪、传感器传来的坐标位移等，进而实现了一个现实世界与虚拟事物的一个映射功能。

从本质上讲，ARCore 在做两件事：

* **在移动设备移动时跟踪它的位置**

ARCore 的运动跟踪技术使用手机摄像头标识兴趣点（称为特征点），并跟踪这些点随着时间变化的移动。 将这些点的移动与手机惯性传感器的读数组合，ARCore 可以在手机移动时确定它的位置和屏幕方向。

* **构建自己对现实世界的理解**

除了标识关键点外，ARCore 还会检测平坦的表面（例如桌子或地面），并估测周围区域的平均光照强度。 这些功能共同让 ARCore 可以构建自己对周围世界的理解。构建出这样一个模型后，可以在上面放置一些虚拟内容了。


## 三、ARCore基本概念

在使用 ARCore 之前，了解一些基本概念会有很大帮助。 这些概念共同介绍了 ARCore 怎样呈现一种逼真的体验，让虚拟内容看起来就像位于真实表面或者处于现实世界中的位置一样。

* **运动跟踪**


当您的手机在现实世界中移动时，ARCore 会通过一个名为并行测距与映射（或 COM）的过程来理解手机相对于周围世界的位置。 ARCore 会检测捕获的摄像头图像中的视觉差异特征（称为特征点），并使用这些点来计算其位置变化。 这些视觉信息将与设备 IMU 的惯性测量结果结合，一起用于估测摄像头随着时间推移而相对于周围世界的姿态（位置和方向）。

通过将渲染 3D 内容的虚拟摄像头的姿态与 ARCore 提供的设备摄像头的姿态对齐，开发者能够从正确的透视角度渲染虚拟内容。 渲染的虚拟图像可以叠加到从设备摄像头获取的图像上，让虚拟内容看起来就像现实世界的一部分一样。

* **环境理解**

ARCore 会通过检测特征点和平面来不断改进它对现实世界环境的理解。

ARCore 可以查找看起来位于常见水平或垂直表面（例如桌子或墙）上的成簇特征点，并让这些表面可以由您的应用用作平面。 ARCore 也可以确定每个平面的边界，并将该信息提供给您的应用。 您可以使用此信息将虚拟物体置于平坦的表面上。

由于 ARCore 使用特征点来检测平面，因此可能无法正确检测像白墙一样没有纹理的平坦表面。


* **光估测**

ARCore 可以检测其环境光线的相关信息，并为您提供给定摄像头图像的平均光强度和色彩校正。 此信息让您能够使用与周围环境相同的光照来照亮您的虚拟物体，提升它们的真实感。

* **用户交互**

ARCore 利用命中测试来获取对应于手机屏幕的 (x,y) 坐标（通过点按或您希望应用支持的任何其他交互提供），并将一条射线投影到摄像头的视野中，返回这条射线贯穿的任何平面或特征点以及交叉位置在现实世界空间中的姿态。 这让用户可以选择环境中的物体或者与它们互动。

* **定向点**

借助定向点，您可以将虚拟物体置于倾斜的表面上。 当您执行会返回特征点的命中测试时，ARCore 将查看附近的特征点并使用这些特征点估算表面在给定特征点处的角度。 然后，ARCore 会返回一个将该角度考虑在内的姿态。

由于 ARCore 使用成簇特征点来检测表面的角度，因此可能无法正确检测像白墙一样没有纹理的表面。

* **锚点和可跟踪对象**

姿态会随着 ARCore 改进它对自身位置和环境的理解而变化。 当您想要放置一个虚拟物体时，您需要定义一个锚点来确保 ARCore 可以跟踪物体随时间推移的位置。 很多时候，您需要基于命中测试返回的姿态创建一个锚点，如用户交互中所述。

姿态会发生变化，这就意味着 ARCore 可能会更新平面和特征点等环境物体随时间推移的位置。 平面和特征点是一种特殊类型的物体，称为可跟踪对象。 顾名思义，ARCore 可以随着时间推移跟踪这些物体。 您可以将虚拟物体锚定到特定的可跟踪对象，确保您的虚拟物体与可跟踪对象之间的关系即使在设备移动时也能保持稳定。 这意味着，如果您将一个虚拟的 Android 小雕像放在您的书桌上，即使 ARCore 稍后调整了与书桌关联的平面的姿态，Android 小雕像仍会看起来位于桌子上。

* **增强图像**

使用增强图像，您可以构建能够响应特定 2D 图像（如产品包装或电影海报）的 AR 应用。 用户可以在将手机的摄像头对准特定图像时触发 AR 体验，例如，他们可以将手机的摄像头对准电影海报，使人物弹出，然后引发一个场景。

可离线编译图像以创建图像数据库，也可以从设备实时添加单独的图像。 注册后，ARCore 将检测这些图像、图像边界，然后返回相应的姿态。

* **共享**

借助 ARCore Cloud Anchor API，您可以创建适用于 Android 和 iOS 设备的协作性或多人游戏应用。

使用云锚点，一台设备可以将锚点和附近的特征点发送到云端进行托管。 可以将这些锚点与同一环境中 Android 或 iOS 设备上的其他用户共享。 这使应用可以渲染连接到这些锚点的相同 3D 对象，从而让用户能够同步拥有相同的 AR 体验。

## 四、ARCore渲染技术

### 使用OpenGL渲染

OpenGL提供高效、简洁的开放图形库接口，要用于三维图形编程。

OpenGL ES（OpenGL for Embedded System）是Open GL三维图形API的子集，针对手机、PAD和游戏主机等嵌入式设备。相对于Open GL来说更轻量级，减少了许多不必要的数据类型，去掉了不必须的功能，对代价大的功能做了限制。

OpenGL ES在ARCore中，结合ARCore对环境的理解，返回的位置和光线等信息，完成2d或者3d图像的渲染。


### 使用Sceneform渲染

Sceneform是google的ARCore开发团队提供的一个方便使用ARCore进行开发的框架，利用Sceneform，无需学习OpenGL即可轻松的在AR和非AR应用中渲染逼真的3D场景，其提供了ArFragment来显示可以渲染虚拟物体的场景，以及相关的一些如模型导入、平面处理、材质自定义、手势控制等功能。


![](https://user-gold-cdn.xitu.io/2018/5/1/1631be7d81f711fa?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)


参考资料：

* [ARCore概览](https://developers.google.com/ar/discover)

